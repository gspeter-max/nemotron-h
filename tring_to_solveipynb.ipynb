{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","mount_file_id":"1bpke4yrFX0D7IaxrlndI54zfsHByMnPl","authorship_tag":"ABX9TyMl9r9so9EsG6/FKdA/ARVf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["! huggingface-cli login"],"metadata":{"id":"e9scdbGrSUKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install bitsandbytes"],"metadata":{"id":"H3qcwnWQT3NV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install trl\n","! pip install -U transformers\n","! pip install -U datasets"],"metadata":{"id":"7Ay7eSyaSa0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from trl import SFTConfig, SFTTrainer\n","from peft import LoraConfig\n","from transformers import AutoModelForCausalLM\n","from transformers import AutoProcessor\n","from transformers import BitsAndBytesConfig\n","import torch\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit = True\n",")\n","\n","dataset = load_dataset('bjoernp/ultrachat_de', split = 'train')\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"mistralai/Mistral-7B-Instruct-v0.1\",\n","    quantization_config = quantization_config,\n","    device_map = 'auto'\n",")\n","processor = AutoProcessor.from_pretrained('mistralai/Mistral-7B-Instruct-v0.1')"],"metadata":{"id":"byLT6z8aoXbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.1')\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","print(processor.__class__.__name__)\n","print(processor.chat_template)\n","print(model.__class__.__name__)\n","print(tokenizer.__class__.__name__)\n","print(tokenizer.chat_template)\n"],"metadata":{"id":"6xp4-XXcSQKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.rename_columns(\n","    {\n","        'response' : 'completion'\n","    }\n",")\n","\n"],"metadata":{"id":"FKvC6d2TaWj1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","sft_config= SFTConfig(\n","        do_train = True,\n","        per_device_train_batch_size = 2,\n","        learning_rate = 0.0001,\n","        weight_decay = 0.002,\n","        num_train_epochs = 12,\n","        warmup_steps = 23\n","    )\n","\n","# for layers in model.named_modules():\n","#     print(layers)\n","\n","lora_config = LoraConfig(\n","        r = 12,\n","        lora_alpha = 23,\n","        lora_dropout = 0.002,\n","        target_modules = 'all-linear'\n","    )\n","\n","sft_trainer = SFTTrainer(\n","        model = model,\n","        processing_class = processor,\n","        args = sft_config,\n","        peft_config = lora_config,\n","        train_dataset = dataset\n","        )\n","\n","sft_trainer.train()"],"metadata":{"id":"pO725pYESSQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gTwBDcEMVJp1"},"execution_count":null,"outputs":[]}]}